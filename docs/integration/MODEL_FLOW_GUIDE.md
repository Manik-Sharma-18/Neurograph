# NeuroGraph Model Flow Guide

## Overview
This document traces the complete execution flow of NeuroGraph from `main.py` through the entire system, showing how data flows through each component during training and evaluation.

## ðŸš€ Entry Point: `main.py`

### CLI Interface & Configuration
```python
main.py
â”œâ”€â”€ Parse CLI arguments (mode, samples, config, etc.)
â”œâ”€â”€ Auto-detect GPU availability (NVIDIA GeForce RTX 3050)
â”œâ”€â”€ Load configuration from config/production.yaml
â””â”€â”€ Initialize random seed (42)
```

**Key Parameters:**
- `--mode`: train/evaluate/benchmark
- `--eval-samples`: Number of evaluation samples
- `--config`: Configuration file path
- `--quick`: Quick evaluation mode

## ðŸ”§ System Initialization Flow

### 1. Training Context Creation
```python
main.py â†’ create_modular_train_context()
â”œâ”€â”€ Load ModularConfig from YAML
â”œâ”€â”€ Setup device (auto-detect CUDA)
â”œâ”€â”€ Initialize core components
â”œâ”€â”€ Setup input/output processing
â”œâ”€â”€ Setup training components
â””â”€â”€ Setup graph structure
```

### 2. Component Initialization Sequence
```python
ModularTrainContext.__init__()
â”œâ”€â”€ ðŸ”§ Core Components
â”‚   â”œâ”€â”€ HighResolutionLookupTables (32Ã—512 resolution)
â”‚   â”œâ”€â”€ ModularPhaseCell (discrete signal computation)
â”‚   â””â”€â”€ VectorizedActivationTable (GPU tensor-based)
â”‚
â”œâ”€â”€ ðŸ”§ Input Processing
â”‚   â”œâ”€â”€ LinearInputAdapter (784â†’200 nodes, learnable projection)
â”‚   â””â”€â”€ MNIST Dataset Loading (60,000 samples)
â”‚
â”œâ”€â”€ ðŸ”§ Output Processing
â”‚   â”œâ”€â”€ OrthogonalClassEncoder (10 classes, 5D encoding)
â”‚   â””â”€â”€ ClassificationLoss (categorical cross-entropy)
â”‚
â”œâ”€â”€ ðŸ”§ Training Components
â”‚   â”œâ”€â”€ GradientAccumulator (8 steps, âˆš8 scaling)
â”‚   â””â”€â”€ BatchController (gradient management)
â”‚
â””â”€â”€ ðŸ”§ Graph Structure
    â”œâ”€â”€ Load/Generate static graph (1000 nodes, 4800 edges)
    â”œâ”€â”€ NodeStore (parameter storage)
    â””â”€â”€ VectorizedForwardEngine (GPU-optimized)
```

## ðŸ“Š Data Flow Architecture

### System Specifications
- **Architecture**: 1000 nodes (200 input, 10 output, 790 intermediate)
- **Vector Dimension**: 5
- **Resolution**: 32 phase bins Ã— 512 magnitude bins
- **Parameters**: 1,584,000 trainable
- **Device**: CUDA (RTX 3050 GPU)

## ðŸ”„ Training Flow (mode=train)

### Single Sample Training Loop
```python
train_single_sample(sample_idx)
â”œâ”€â”€ 1. Input Processing
â”‚   â”œâ”€â”€ Get MNIST sample (784 pixels)
â”‚   â”œâ”€â”€ LinearInputAdapter.get_input_context()
â”‚   â”‚   â”œâ”€â”€ Linear projection: 784 â†’ 200Ã—5 = 1000 values
â”‚   â”‚   â”œâ”€â”€ Phase-magnitude quantization
â”‚   â”‚   â””â”€â”€ Return: {node_id: (phase_indices, mag_indices)}
â”‚   â””â”€â”€ Target label extraction
â”‚
â”œâ”€â”€ 2. Forward Pass
â”‚   â”œâ”€â”€ Convert to string node IDs (n0, n1, ...)
â”‚   â”œâ”€â”€ VectorizedForwardEngine.forward_pass_vectorized()
â”‚   â”‚   â”œâ”€â”€ Clear activation table
â”‚   â”‚   â”œâ”€â”€ Inject input context (batch GPU operation)
â”‚   â”‚   â”œâ”€â”€ Propagation loop (2-25 timesteps):
â”‚   â”‚   â”‚   â”œâ”€â”€ Get active nodes (GPU tensors)
â”‚   â”‚   â”‚   â”œâ”€â”€ Check output activation (vectorized)
â”‚   â”‚   â”‚   â”œâ”€â”€ VectorizedPropagationEngine.propagate_vectorized()
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Static propagation (graph edges)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Dynamic radiation (phase alignment)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Batch phase cell computation
â”‚   â”‚   â”‚   â”œâ”€â”€ Clear previous activations
â”‚   â”‚   â”‚   â”œâ”€â”€ Inject new activations (batch)
â”‚   â”‚   â”‚   â””â”€â”€ Decay and prune (vectorized)
â”‚   â”‚   â””â”€â”€ Early termination on output activation
â”‚   â””â”€â”€ Extract output signals from final state
â”‚
â”œâ”€â”€ 3. Loss Computation
â”‚   â”œâ”€â”€ Get class encodings (orthogonal 5D vectors)
â”‚   â”œâ”€â”€ Compute logits via cosine similarity
â”‚   â”œâ”€â”€ Categorical cross-entropy loss
â”‚   â””â”€â”€ Accuracy calculation
â”‚
â”œâ”€â”€ 4. Backward Pass (Discrete Gradient Approximation)
â”‚   â”œâ”€â”€ Compute upstream gradients (loss derivatives)
â”‚   â”œâ”€â”€ For each output node:
â”‚   â”‚   â”œâ”€â”€ Get current discrete parameters
â”‚   â”‚   â”œâ”€â”€ Compute continuous gradients (lookup tables)
â”‚   â”‚   â””â”€â”€ Store node gradients
â”‚   â””â”€â”€ Vectorized intermediate node credit assignment
â”‚
â””â”€â”€ 5. Parameter Updates
    â”œâ”€â”€ Gradient accumulation (8 steps)
    â”œâ”€â”€ Apply continuousâ†’discrete gradient conversion
    â”œâ”€â”€ Update NodeStore parameters (modular arithmetic)
    â””â”€â”€ Learning rate: 0.0028 (âˆš8 scaled from 0.001)
```

## ðŸ“ˆ Evaluation Flow (mode=evaluate)

### Batch Evaluation Process
```python
evaluate_accuracy(num_samples)
â”œâ”€â”€ Set model to eval mode
â”œâ”€â”€ Sample random indices from dataset
â”œâ”€â”€ For each sample:
â”‚   â”œâ”€â”€ Get input context (no gradients)
â”‚   â”œâ”€â”€ Forward pass (same as training)
â”‚   â”œâ”€â”€ Compute prediction (argmax of logits)
â”‚   â””â”€â”€ Compare with ground truth
â”œâ”€â”€ Calculate accuracy percentage
â””â”€â”€ Return final accuracy
```

## ðŸ§  Core Data Transformations

### 1. Input Transformation
```
MNIST Image (28Ã—28=784 pixels)
    â†“ LinearInputAdapter
200 nodes Ã— 5 dimensions = 1000 values
    â†“ Phase-Magnitude Quantization
Phase indices [0-31] + Magnitude indices [0-511]
    â†“ GPU Tensor Conversion
CUDA tensors for batch processing
```

### 2. Forward Propagation
```
Input Context: {node_id: (phase_idx, mag_idx)}
    â†“ VectorizedActivationTable
GPU tensors [max_nodes, vector_dim]
    â†“ Propagation Loop (2-25 timesteps)
Active nodes â†’ Targets â†’ New activations
    â†“ Early Termination
Output nodes activated â†’ Extract signals
```

### 3. Signal Processing
```
Discrete Indices (phase, magnitude)
    â†“ HighResolutionLookupTables
Continuous signals (cos/sin values)
    â†“ Cosine Similarity
Logits for each class
    â†“ Softmax + Cross-entropy
Loss value + Gradients
```

## âš¡ GPU Acceleration Details

### Vectorized Operations
- **Activation Table**: GPU tensors instead of Python dictionaries
- **Batch Processing**: Multiple nodes processed simultaneously
- **Memory Pre-allocation**: Efficient tensor reuse
- **Vectorized Propagation**: Parallel neighbor computation

### Memory Usage
- **Total GPU Memory**: 8.76 MB allocated
- **Activation Table**: 0.10 MB
- **Forward Engine**: 8.66 MB (batch tensors + propagation)
- **Device**: NVIDIA GeForce RTX 3050 Laptop GPU

## ðŸ”§ Key Components Deep Dive

### VectorizedForwardEngine
- **Purpose**: GPU-optimized forward propagation
- **Key Features**: Batch processing, early termination, memory efficiency
- **Performance**: 2-5x speedup over CPU version

### VectorizedActivationTable
- **Purpose**: GPU tensor-based activation management
- **Replaces**: Python dictionary operations
- **Performance**: 10x+ faster activation tracking

### ModularPhaseCell
- **Purpose**: Discrete signal computation
- **Method**: Direct phase-magnitude transfer with modular arithmetic
- **Resolution**: 32Ã—512 bins for high precision

### LinearInputAdapter
- **Purpose**: Learnable input transformation
- **Method**: Neural network projection (NOT PCA)
- **Parameters**: 784Ã—1000 = 784,000 learnable weights

## ðŸŽ¯ Execution Examples

### Quick Evaluation
```bash
python main.py --mode evaluate --eval-samples 5 --quick
```
**Flow**: main.py â†’ evaluate_model() â†’ trainer.evaluate_accuracy(5) â†’ 40% accuracy

### Training Session
```bash
python main.py --mode train --epochs 10
```
**Flow**: main.py â†’ run_training() â†’ trainer.train() â†’ epoch loop â†’ sample loop

### Benchmarking
```bash
python main.py --mode benchmark --samples 100
```
**Flow**: main.py â†’ run_benchmark() â†’ performance measurement â†’ timing statistics

## ðŸ“Š Performance Characteristics

### Typical Execution Times (RTX 3050)
- **Initialization**: ~2-3 seconds
- **Forward Pass**: ~0.1-0.3 seconds per sample
- **Training Step**: ~0.2-0.5 seconds per sample
- **Evaluation**: ~0.05-0.1 seconds per sample

### Memory Efficiency
- **Base Memory**: ~6.1 MB system memory
- **GPU Memory**: 8.76 MB CUDA memory
- **Parameter Storage**: 1,584,000 discrete indices
- **Batch Tensors**: Pre-allocated for efficiency

## ðŸ”„ Configuration System

### Production Configuration (config/production.yaml)
```yaml
architecture:
  total_nodes: 1000
  vector_dim: 5
  
resolution:
  phase_bins: 32
  mag_bins: 512
  
training:
  gradient_accumulation:
    enabled: true
    accumulation_steps: 8
```

### Dynamic Configuration Loading
- Auto-detection of optimal settings
- Device-specific optimizations
- Memory fraction management (80% GPU usage)

## ðŸš€ Optimization Features

### GPU Acceleration
- CUDA tensor operations throughout
- Vectorized batch processing
- Memory-efficient tensor pooling
- Optimized GPU memory layout

### Discrete Computation
- High-resolution phase-magnitude representation
- Modular arithmetic for parameter updates
- Continuous gradient approximation
- Efficient lookup table operations

This flow guide provides a complete picture of how NeuroGraph processes data from input to output, leveraging GPU acceleration and discrete computation for efficient neural network training and evaluation.
